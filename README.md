# ğŸ“„ Retrieval-Augmented Chatbot API

A **FastAPI-based RAG (Retrieval-Augmented Generation) chatbot** that answers user queries based on information extracted from a local `resume.json`.  
Supports rate-limiting, CORS for frontend integration, and retrieval with Hugging Face embeddings + Chroma vector store.

---

## ğŸš€ Features
âœ… Retrieval-Augmented Generation using `langgraph`  
âœ… OpenAI Sentiment embeddings
âœ… Chroma vector database for document retrieval  
âœ… FastAPI REST API ready for frontend integration  
âœ… CORS configured for specific frontend URLs  
âœ… Rate-limited endpoint to prevent abuse (10 requests per hour per IP)  
âœ… Cleaned AI responses (removes `<think>` tags)

---

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ main.py                 # FastAPI app and chatbot API
â”œâ”€â”€ resume.json             # JSON knowledge base for retrieval
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Technologies Used
- **FastAPI** - RESTful API framework
- **slowapi** - Rate limiting
- **langchain_huggingface / langchain_chroma** - Embeddings & Vector DB
- **Groq Deepseek model** - LLM backend
- **RecursiveCharacterTextSplitter** - Chunking JSON documents
- **LangChain Hub Prompt** - For RAG prompt template
- **CORS Middleware** - Frontend integration

---

## ğŸ”‘ API Endpoint

### `POST /ask`
- **Description**: Ask the chatbot a question and get a generated answer
- **Rate Limit**: 10 requests per hour per IP
- **Request JSON**:
```json
{
  "message": "Your question here"
}
```
- **Response JSON**:
```json
{
  "answer": "AI generated answer based on resume knowledge"
}
```

---

## ğŸŒ CORS Allowed Origins:
- `http://localhost:5173`
- `https://pandalow.github.io/`

---

## ğŸ“– How It Works (RAG Pipeline)
1. Load and split `resume.json`
2. Store chunks in a Chroma vector database
3. Accept user question
4. Perform similarity search to retrieve relevant context
5. Format context and question into a RAG prompt
6. Generate response using the LLM (`deepseek-r1-distill-qwen-32b`)
7. Clean response (remove `<think>` tags)
8. Return the answer

---

## ğŸ›  Running the Project

### 1ï¸âƒ£ Install Requirements
```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Start the API Server
```bash
uvicorn main:app --reload
```

---

## ğŸ“ˆ Example Usage (curl)
```bash
curl -X POST "http://localhost:8000/ask" \
     -H "Content-Type: application/json" \
     -d '{"message": "Tell me about your backend skills."}'
```

---

## âš ï¸ Rate Limiting
- Limit: `10/hour` per IP
- Returns **429 Too Many Requests** if exceeded

---

## ğŸ“œ Notes
âœ… LLM model used: `deepseek-r1-distill-qwen-32b` via Groq  
âœ… Embedding model: `sentence-transformers/paraphrase-MiniLM-L6-v2`  
âœ… Vector DB: `Chroma`  
âœ… JSON schema customizable via JQ syntax

---

## ğŸ¤ License
MIT License â€” Feel free to use and modify.
